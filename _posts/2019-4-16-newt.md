---
layout: post
title:  "Optimization Series: #2 Newton's Method"
date:   2019-04-15 5:37:44 -0500
categories: stuff
---
{% include mathjax.html %}
# Newton's Method for Root Finding

Given function defined on domain $$f: (a,b) \rightarrow \mathbb{R} $$ where $$f \in D(a,b)$$
our goal is to find $$x^* \in (a,b)$$ such that $$f(x^*) = 0$$.

Let's define a function to work with and investigate: $$f: (2,6) \rightarrow \mathbb{R}$$ $$f(x) = -x \sin(x)$$

Newtons method seeks to find a root by iterating over the equation $$ x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}$$

In this case we can use basic calculus to derive a general form $$f'(x) = -\sin(x) + -x\cos(x) $$ Thus the form we need is $$ x_{n+1} = x_n - \frac{x_n\sin(x_n)}{\sin(x_n) + x_n\cos(x_n)}$$
Guess $$x_0 = 3$$ as the average of the interval.


```python
from numpy import sin,cos
def f(x):
    return -x*sin(x)
x = 3
for i in range(100):
    x -= (x*sin(x)) / (sin(x) + x*cos(x))
print('root = ' + str(x))
```

    root = 3.141592653589793


As we can see, $$x^* \approx \pi$$ We can verify this analytically. $$sin(\pi) = 0 \implies -\pi sin(\pi) = 0$$ so we can say $$x^* = \pi$$

# Newton's Method for Optimization

Can we adapt this to find $$x^*$$ where  $$f'(x^*) = 0 \ ?$$

The answer is yes, in fact the only extra work is requires is calculating $$ f''(x_k) $$ each iteration. We can just reapply the definitions. $$x_{n+1} = x_n - \frac{f'(x_n)}{f''(x_n)}$$

Case: $$f(x) = -x \sin(x)$$ from before: $$f'(x) = -\sin(x) + -x\cos(x) $$ and $$f''(x) = -\cos(x) - \cos(x) + x \sin(x) = -2 \cos(x) + x\sin(x)$$
So we iterate over
$$x_{n+1} = x_n - \frac{\sin(x) + x\cos(x)}{2 \cos(x) - x\sin(x)}$$


```python
x = 4
for i in range(100):
    x -= (sin(x) + x*cos(x)) / (2*cos(x) - x*sin(x))
print('root = ' + str(x))
```

    root = 4.913180439434884



```python
import matplotlib.pyplot as plt
from numpy import linspace
xs = linspace(2,6,1000)
ys = f(xs)
plt.plot(xs,ys)

plt.plot(x,f(x),'ro')
```






<img src="{{site.baseurl}}/assets/output_11_1.png">


We have succesfully maximized our function!
